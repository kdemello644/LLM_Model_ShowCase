{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "57f21058",
      "metadata": {
        "id": "57f21058"
      },
      "source": [
        "# Text analysis from (Stock Market News Data in Portuguese | Kaggle)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81a66129",
      "metadata": {
        "id": "81a66129"
      },
      "source": [
        "### By: Kevin De Mello Santamaria\n",
        "#### Date: 12/12/2023"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f6d77f8",
      "metadata": {
        "id": "1f6d77f8"
      },
      "source": [
        "## LangChain Model Description\n",
        "\n",
        "The LangChain model is a comprehensive language processing system tailored for financial phrases in Portuguese. Leveraging state-of-the-art models and libraries, it seamlessly integrates text summarization, keyword extraction, and sentiment analysis to provide a holistic understanding of financial text data.\n",
        "\n",
        "#### 1. Text Summarization using Facebook BART Large CNN Model:\n",
        "\n",
        "Model use Facebook BART Large CNN model for text summarization put as a tool in the model. This pre-trained model excels at condensing lengthy financial phrases into concise and informative summaries, capturing the essential meaning and context.\n",
        "\n",
        "#### 2. Keyword Extraction with KeyBert Library:\n",
        "\n",
        "To identify crucial terms and concepts within the financial phrases, I used modelthe KeyBert library to extract words. KeyBert utilizes BERT-based embeddings to extract keywords, offering a nuanced representation of the most significant information present in the text.\n",
        "\n",
        "#### 3. Sentiment Analysis using TextBlob Library:\n",
        "\n",
        "Understanding the sentiment behind financial statements is essential. I implemented TextBlob library for sentiment analysis, assigning sentiment labels such as positive, negative, or neutral to each financial phrase. This feature aids in gauging the overall sentiment expressed in the dataset.\n",
        "\n",
        "#### Dataset Source:\n",
        "\n",
        "The LangChain model is specifically designed for financial phrases sourced from the \"Financial Phrase Bank - Portuguese Translation\" dataset available on Kaggle. This dataset contains a diverse collection of financial statements and expressions in Portuguese, providing a robust foundation for the model's training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12edb97b-e04e-4915-8a4c-8390049b713c",
      "metadata": {
        "id": "12edb97b-e04e-4915-8a4c-8390049b713c"
      },
      "outputs": [],
      "source": [
        "! python -m venv venv # Create a venv\n",
        "! source ./venv/bin/activate\n",
        "! pip install -r requirements.txt # Install all libraries from txt\n",
        "! python -m pip install jupyter # Install Jupyter Notebook\n",
        "! python -m ipykernel install --user --name=llm-virtual-venv # Declare a kernel for Jupyternotebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "611d4564",
      "metadata": {
        "id": "611d4564"
      },
      "source": [
        "##### In case you need a OpenAI Key, kaggle username and password Consult Kevin\n",
        "Cell number & WhatsAPP: + 55 16 99740 8851"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fde74de9",
      "metadata": {
        "id": "fde74de9"
      },
      "source": [
        "#### Insert here Open AI Key, kaggle username and key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68d7846e",
      "metadata": {
        "id": "68d7846e"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = 'INSERT_YOUR_OPEN_AI_KEY'\n",
        "KAGGLE_USERNAME = \"INSERT_YOUR_KAGGLE_USERNAME\"\n",
        "KAGGLE_KEY = \"INSERT_YOUR_KAGGLE_KEY\"\n",
        "DOWNLOAD_DIR = 'data_financial/'\n",
        "COMPETITION_NAME = 'mateuspicanco/financial-phrase-bank-portuguese-translation'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9930d4bb",
      "metadata": {
        "id": "9930d4bb"
      },
      "source": [
        "#### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3708675a",
      "metadata": {
        "id": "3708675a"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import json\n",
        "import openai\n",
        "import os\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2392373e",
      "metadata": {
        "id": "2392373e"
      },
      "outputs": [],
      "source": [
        "from typing import Type\n",
        "from pydantic import BaseModel, Field\n",
        "from textblob import TextBlob\n",
        "from sklearn.metrics import classification_report\n",
        "from keybert import KeyBERT\n",
        "from operator import itemgetter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6cae812",
      "metadata": {
        "id": "d6cae812"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import BaseTool\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.tools import BaseTool\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from transformers import  BartTokenizer, BartForConditionalGeneration\n",
        "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
        "from langchain.agents import Tool\n",
        "from langchain_experimental.agents import create_csv_agent\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents.agent_types import AgentType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcb9e0c4-072e-44cf-b7e1-3f17bccabc92",
      "metadata": {
        "id": "fcb9e0c4-072e-44cf-b7e1-3f17bccabc92"
      },
      "outputs": [],
      "source": [
        "def remove_zip_files(directory):\n",
        "   for root, dirs, files in os.walk(directory):\n",
        "       for file in files:\n",
        "           if file.lower().endswith('.zip'):\n",
        "               file_path = os.path.join(root, file)\n",
        "               os.remove(file_path)\n",
        "\n",
        "\n",
        "def get_filename():\n",
        "    os.environ['KAGGLE_USERNAME'] = KAGGLE_USERNAME\n",
        "    os.environ['KAGGLE_KEY'] = KAGGLE_KEY\n",
        "\n",
        "    api = KaggleApi()\n",
        "    api.authenticate()\n",
        "\n",
        "\n",
        "    shutil.rmtree(DOWNLOAD_DIR, ignore_errors=True)\n",
        "    os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
        "\n",
        "    api.dataset_download_files(COMPETITION_NAME, path = DOWNLOAD_DIR)\n",
        "\n",
        "\n",
        "    with ZipFile(f'{DOWNLOAD_DIR}{os.listdir(DOWNLOAD_DIR)[0]}', 'r') as zObject:\n",
        "        zObject.extractall(path=f'{DOWNLOAD_DIR}')\n",
        "    remove_zip_files(DOWNLOAD_DIR)\n",
        "\n",
        "    extension = 'csv'\n",
        "    os.chdir(DOWNLOAD_DIR)\n",
        "    result = glob.glob('*.{}'.format(extension))\n",
        "    return f'{result[0]}'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "573c7648-0091-40b0-b8f1-b266e2db5bf7",
      "metadata": {
        "id": "573c7648-0091-40b0-b8f1-b266e2db5bf7"
      },
      "outputs": [],
      "source": [
        "DF_PATH = get_filename()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d02ce1f",
      "metadata": {
        "id": "3d02ce1f"
      },
      "source": [
        "#### Functions to summarize the text, get key words, do a sentiment analysis and score the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1edd79b5",
      "metadata": {
        "id": "1edd79b5"
      },
      "outputs": [],
      "source": [
        "#Get Text Summary\n",
        "def summarize_text(text):\n",
        "    model_name = 'facebook/bart-large-cnn'\n",
        "    tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "    model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "    # Tokenize and encode the text\n",
        "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "\n",
        "    # Generate summary\n",
        "    summary_ids = model.generate(inputs, max_length=150, min_length=50, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "\n",
        "    # Decode the summary\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a624d9de",
      "metadata": {
        "id": "a624d9de"
      },
      "outputs": [],
      "source": [
        "# Get Keywordsd from text\n",
        "def get_keyword(text):\n",
        "    kw_model = KeyBERT()\n",
        "    return list(dict(kw_model.extract_keywords(text)).keys())[:3]\n",
        "\n",
        "# Get sentiment as Positive, Negative and Neutral\n",
        "def get_sentiment(text):\n",
        "    blob = TextBlob(text)\n",
        "\n",
        "    return get_Analysis(blob.sentiment.polarity)\n",
        "\n",
        "def get_Analysis(score):\n",
        "  if score < 0:\n",
        "    return 'negative'\n",
        "  elif score == 0:\n",
        "    return 'neutral'\n",
        "  else:\n",
        "    return 'positive'\n",
        "\n",
        "def get_accuracy(prediction,labeled):\n",
        "    return classification_report(prediction,labeled, target_names=['negative', 'neutral', 'positive'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81282456",
      "metadata": {
        "id": "81282456"
      },
      "source": [
        "#### Tool declaration for LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72cb88ff",
      "metadata": {
        "id": "72cb88ff"
      },
      "outputs": [],
      "source": [
        "class SummarizeText(BaseTool):\n",
        "    name = \"Summarize Text\"\n",
        "    description = \"use this tool when you need to make a summary of a text\"\n",
        "\n",
        "    def _run(self, text: str):\n",
        "        return summarize_text(text)\n",
        "\n",
        "    def _arun(self, text : str):\n",
        "        raise NotImplementedError(\"This tool does not support async\")\n",
        "\n",
        "class KeyWordsText(BaseTool):\n",
        "    name = \"Key Words Text\"\n",
        "    description = \"use this tool when you need search keywords from a text\"\n",
        "\n",
        "    def _run(self, text : str):\n",
        "        return get_keyword(text)\n",
        "\n",
        "    def _arun(self, text : str):\n",
        "        raise NotImplementedError(\"This tool does not support async\")\n",
        "\n",
        "\n",
        "class SentimentAnalysis(BaseTool):\n",
        "    name = \"Sentiment Analysis\"\n",
        "    description = \"use this tool when you need to do a sentiment analysis\"\n",
        "\n",
        "    def _run(self, text : str):\n",
        "        return get_sentiment(text)\n",
        "\n",
        "    def _arun(self, text : str):\n",
        "        raise NotImplementedError(\"This tool does not support async\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b74fefde",
      "metadata": {
        "id": "b74fefde"
      },
      "outputs": [],
      "source": [
        "csv_agent = create_csv_agent(\n",
        "        ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\", openai_api_key=OPENAI_API_KEY),\n",
        "        DF_PATH,\n",
        "        verbose=True,\n",
        "        agent_type=AgentType.OPENAI_FUNCTIONS,\n",
        "    )\n",
        "\n",
        "Pandas_Df_Financial = Tool(name='csv_agent',func=csv_agent.run,description='Useful to read csv file')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36250eb5",
      "metadata": {
        "id": "36250eb5"
      },
      "outputs": [],
      "source": [
        "tools = [SummarizeText(),KeyWordsText(),SentimentAnalysis(),Pandas_Df_Financial]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a59d1d9d",
      "metadata": {
        "id": "a59d1d9d"
      },
      "source": [
        "#### LLM Lanchain Declaration\n",
        "###### For this mode I used a ChatGPT model using a conversational memory reading the dataset from a tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "219900b7",
      "metadata": {
        "id": "219900b7"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(\n",
        "        openai_api_key = OPENAI_API_KEY,\n",
        "        temperature=0,\n",
        "        model_name='gpt-3.5-turbo'\n",
        ")\n",
        "\n",
        "conversational_memory = ConversationBufferWindowMemory(\n",
        "        memory_key='chat_history',\n",
        "        k=5,\n",
        "        return_messages=True\n",
        ")\n",
        "\n",
        "agent = initialize_agent(\n",
        "    agent='chat-conversational-react-description',\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    verbose=False,\n",
        "    max_iterations=3,\n",
        "    early_stopping_method='generate',\n",
        "    memory=conversational_memory\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0e73000",
      "metadata": {
        "id": "c0e73000"
      },
      "source": [
        "#### Prompts for test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d944d548",
      "metadata": {
        "id": "d944d548",
        "outputId": "b235c21e-c396-48a2-b6e7-45a88646b9b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `python_repl_ast` with `{'query': 'df.shape[0]'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m4845\u001b[0m\u001b[32;1m\u001b[1;3mThe number of rows in the dataframe is 4845.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'The number of rows in the dataset is 4845.'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent(\"How many rows there are in the dataset\")['output'] # Test dataframe lecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b06905b8",
      "metadata": {
        "id": "b06905b8",
        "outputId": "2adabc2d-f287-4f7e-ca88-4d7715103399"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThe columns in the dataframe are \"y\", \"text\", and \"text_pt\".\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"The columns in the dataframe are 'y', 'text', and 'text_pt'.\""
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent(\"Show me the columns of the dataframe\")['output'] # Test manipulation of dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ca233bc",
      "metadata": {
        "id": "9ca233bc",
        "outputId": "02860ccc-bc6a-4ed3-8ae6-ec5971617277"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"The summary of the text column is: Use the weekly Newsquiz to test your knowledge of stories you saw on CNN.com and CNN iReport.com for a chance to win a $1,000 gift card to help support CNN's iReport project.\""
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent(\"Make me a summary of the text column\")['output'] # Testing text summary tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65af7ab7",
      "metadata": {
        "id": "65af7ab7",
        "outputId": "d45a1ccd-923b-4f61-ea45-5b75d2a77826"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The summary of the text_pt column is: text_PT is a text-based search engine. Text-based searches can be used to search for text. text-search.com is a search engine that searches for text in text format.'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent(\"Make me a summary of the text_pt column\")['output'] # Testing text summary tool for portuguese"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7b5b890",
      "metadata": {
        "id": "b7b5b890",
        "outputId": "4a9e8cb1-7609-4b40-d52a-4376dc4591ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"The summary of the text column's first cell is: Use the weekly Newsquiz to test your knowledge of stories you saw on CNN.com and CNN iReport. You could win a $1,000 gift card to help support CNN's iReport project.\""
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent(\"Make me a summary of the text column first cell\")['output'] # Testing text summary tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45180052",
      "metadata": {
        "id": "45180052",
        "outputId": "20094d4d-e7d8-41f6-bb93-fc5f060a45d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"The sentiment analysis of the text column's first item is positive.\""
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent(\"Make me a sentiment analysis of the text column firt item\")['output'] # Testing text sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49517eac",
      "metadata": {
        "id": "49517eac",
        "outputId": "a9fc7d2c-5b79-4cb3-d2c5-76865a1dc62f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"The keywords extracted from the text column's first item are 'cnn', 'newsquiz', and 'stories'.\""
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent(\"Make me a keyword extraction of the text column firt item\")['output'] # Testing Keywords extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "000801ba-40d0-4d9e-9bbf-8c17a47c5e75",
      "metadata": {
        "id": "000801ba-40d0-4d9e-9bbf-8c17a47c5e75",
        "outputId": "f641a790-3f6c-44c5-bc83-be0f9734eeee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The sentiment analysis of the entire dataset is neutral.'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent(\"Make me a sentiment analysis from all dataset\")['output'] # Testing sentiment analysis from all dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8ee45c4-3f5b-4906-9117-b78d976e3b3c",
      "metadata": {
        "id": "f8ee45c4-3f5b-4906-9117-b78d976e3b3c",
        "outputId": "4f92d7aa-aa79-4096-bb08-d360219fa11c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"The summary of all values in the text column is: Use the weekly Newsquiz to test your knowledge of stories you saw on CNN.com and CNN iReport. You could win a $1,000 gift card to help support CNN's iReport project.\""
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent(\"Make me a summary from all values of text column\")['output'] # Testing all dataset summary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5603ab1b",
      "metadata": {
        "id": "5603ab1b"
      },
      "source": [
        "### Testing sentiment analysis accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e8cd02d",
      "metadata": {
        "id": "1e8cd02d"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(DF_PATH)\n",
        "df['sentiment'] = df['text'].apply(get_sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cacd461f",
      "metadata": {
        "id": "cacd461f",
        "outputId": "287e00db-e008-41d5-d50e-988a0e680029"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.38      0.30      0.34       761\n",
            "     neutral       0.54      0.63      0.58      2468\n",
            "    positive       0.43      0.36      0.39      1616\n",
            "\n",
            "    accuracy                           0.49      4845\n",
            "   macro avg       0.45      0.43      0.44      4845\n",
            "weighted avg       0.48      0.49      0.48      4845\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(get_accuracy(df['sentiment'],df['y']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33ede4bd-36db-4e0a-b5b1-c938719fd9bb",
      "metadata": {
        "id": "33ede4bd-36db-4e0a-b5b1-c938719fd9bb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}